{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "import torch\n",
    "\n",
    "# data\n",
    "from datasets import load_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator\n",
    "\n",
    "# model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# training and evaluation\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import Accuracy, Fbeta, Precision, Recall\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1 1.0.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, pl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassfier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, padding_idx, hidden_size=768, num_layers=1, dropout=0.10, num_classes=3):\n",
    "        super(GRUClassfier, self).__init__()\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
    "        # gru module\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "#             dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # full connected layer as classifier\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(in_features=2*num_layers*hidden_size, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=num_classes)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # get the embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # pass the embedding and initial hidden states to GRU (cell state will be same as hidden states) \n",
    "        _, outputs = self.gru(embedded, hidden)\n",
    "        \n",
    "        # outputs.shape -> [2*num_layers, batch_size, hidden_size] convert it into batch_first format\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "        outputs = outputs.reshape(batch_size, -1)\n",
    "#         print(outputs.shape)\n",
    "        \n",
    "        # last hidden states of the BidirectionalGRU will be passed to classifier will returns logits \n",
    "        logits = self.fc(outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation for GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fields\n",
    "TEXT = Field(lower=True, tokenize=\"spacy\", batch_first=True)\n",
    "LABEL = LabelField(batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [(\"id\", None), (\"Tweets\", TEXT), (\"Label\", LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train data\n",
    "train = TabularDataset(\n",
    "    path=\"../dataset/train.csv\",\n",
    "    format=\"CSV\",\n",
    "    fields=fields,\n",
    "    skip_header=True,\n",
    "\n",
    ")\n",
    "# load the test data\n",
    "test = TabularDataset(\n",
    "    path=\"../dataset/test.csv\",\n",
    "    format=\"CSV\",\n",
    "    fields=fields,\n",
    "    skip_header=True,\n",
    "\n",
    ")\n",
    "# take some data from test for validation during training\n",
    "test, val = test.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(text.vocab), len(target.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data loaders\n",
    "train_loader, val_loader, test_loader = BucketIterator.splits(\n",
    "    datasets=(train, val, test),\n",
    "    batch_size=64,\n",
    "    device=device,\n",
    "    shuffle=True,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 35]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.Tweets.shape, batch.Label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRUClassfier(\n",
    "    vocab_size=len(TEXT.vocab),\n",
    "    embedding_dim=300,\n",
    "    padding_idx=TEXT.vocab[TEXT.pad_token],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1536])\n",
      "torch.Size([64, 3])\n"
     ]
    }
   ],
   "source": [
    "logits = gru(batch.Tweets)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(LightningModel, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits  = self.model(x)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(params=self.parameters(), lr=1e-1)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch.Tweets, batch.Label\n",
    "        y_ = self(x)\n",
    "        loss = F.cross_entropy(y_, y)\n",
    "        acc = accuracy_score(y, y_.argmax(dim=1))\n",
    "        f1 = f1_score(y, y_.argmax(dim=1), average=\"macro\")\n",
    "        wandb.log({\"loss\":loss, \"accuraccy\":acc, \"f1_score\":f1})\n",
    "        return {\"loss\":loss, \"accuraccy\":acc, \"f1_score\":f1}\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return val_loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch.Tweets, batch.Label\n",
    "        y_ = self(x)\n",
    "        loss = F.cross_entropy(y_, y)\n",
    "        acc = accuracy_score(y, y_.argmax(dim=1))\n",
    "        f1 = f1_score(y, y_.argmax(dim=1), average=\"macro\")\n",
    "        return {\"val_loss\":loss, \"val_accuracy\":torch.tensor([acc]), \"val_f1\":torch.tensor([f1])}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_accuracy'] for x in outputs]).mean()\n",
    "        avg_f1 = torch.stack([x['val_f1'] for x in outputs]).mean()\n",
    "        wandb.log({\"val_loss\":avg_loss, \"val_accuracy\":avg_acc, \"val_f1\":avg_f1})\n",
    "        return {\"val_loss\":avg_loss, \"val_accuracy\":avg_acc, \"val_f1\":avg_f1}\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return test_loader\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch.Tweets, batch.Label\n",
    "        y_ = self(x)\n",
    "        loss = F.cross_entropy(y_, y)\n",
    "        acc = accuracy_score(y, y_.argmax(dim=1))\n",
    "        f1 = f1_score(y, y_.argmax(dim=1), average=\"macro\")\n",
    "        precision = precision_score(y, y_.argmax(dim=1), average=\"macro\")\n",
    "        recall = recall_score(y, y_.argmax(dim=1), average=\"macro\")\n",
    "        return {\"test_loss\":loss, \"test_precision\":precision, \"test_recall\":recall, \"test_acc\":acc, \"test_f1\":f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningModel(model=gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger(\n",
    "    name=\"gru\",\n",
    "    save_dir=\"./models/\",\n",
    "    project=\"hate-speech-detection\",\n",
    "    log_model=True,\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.005,\n",
    ")\n",
    "checkpoints = ModelCheckpoint(\n",
    "    filepath=\"./models/{epoch}-{val_accuracy}\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    checkpoint_callback=checkpoints,\n",
    "    default_root_dir=\"./models/\",\n",
    "    max_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 287194<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>./models/wandb/run-20201114_205641-3n01dpzq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>./models/wandb/run-20201114_205641-3n01dpzq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">gru</strong>: <a href=\"https://wandb.ai/macab/hate-speech-detection/runs/3n01dpzq\" target=\"_blank\">https://wandb.ai/macab/hate-speech-detection/runs/3n01dpzq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gru</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/macab/hate-speech-detection\" target=\"_blank\">https://wandb.ai/macab/hate-speech-detection</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/macab/hate-speech-detection/runs/o2sh7hkt\" target=\"_blank\">https://wandb.ai/macab/hate-speech-detection/runs/o2sh7hkt</a><br/>\n",
       "                Run data is saved locally in <code>./models/wandb/run-20201114_205806-o2sh7hkt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | GRUClassfier | 12 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 0it [00:00, ?it/s]torch.Size([64, 1536])\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  8.24it/s]torch.Size([64, 1536])\n",
      "Epoch 0:   0%|          | 0/212 [00:00<?, ?it/s]                      torch.Size([64, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The validation_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/212 [00:01<06:05,  1.73s/it, loss=1.089, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   1%|          | 2/212 [00:03<05:21,  1.53s/it, loss=11.069, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   1%|▏         | 3/212 [00:04<04:39,  1.34s/it, loss=11.908, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   2%|▏         | 4/212 [00:04<03:50,  1.11s/it, loss=18.305, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   2%|▏         | 5/212 [00:04<03:19,  1.04it/s, loss=15.485, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   3%|▎         | 6/212 [00:05<02:59,  1.15it/s, loss=13.110, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   3%|▎         | 7/212 [00:05<02:44,  1.25it/s, loss=11.378, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   4%|▍         | 8/212 [00:06<02:33,  1.33it/s, loss=10.081, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   4%|▍         | 9/212 [00:06<02:23,  1.41it/s, loss=9.065, v_num=7hkt] torch.Size([64, 1536])\n",
      "Epoch 0:   5%|▍         | 10/212 [00:06<02:17,  1.47it/s, loss=8.251, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   5%|▌         | 11/212 [00:07<02:10,  1.53it/s, loss=7.583, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   6%|▌         | 12/212 [00:07<02:06,  1.59it/s, loss=7.028, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   6%|▌         | 13/212 [00:08<02:03,  1.62it/s, loss=6.561, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   7%|▋         | 14/212 [00:08<01:58,  1.67it/s, loss=6.161, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   7%|▋         | 15/212 [00:08<01:55,  1.71it/s, loss=5.801, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   8%|▊         | 16/212 [00:09<01:52,  1.74it/s, loss=5.487, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   8%|▊         | 17/212 [00:09<01:50,  1.77it/s, loss=5.212, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   8%|▊         | 18/212 [00:10<01:47,  1.80it/s, loss=4.968, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   9%|▉         | 19/212 [00:10<01:45,  1.82it/s, loss=4.753, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:   9%|▉         | 20/212 [00:10<01:43,  1.85it/s, loss=4.556, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  10%|▉         | 21/212 [00:11<01:41,  1.88it/s, loss=4.546, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  10%|█         | 22/212 [00:11<01:39,  1.90it/s, loss=3.534, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  11%|█         | 23/212 [00:11<01:37,  1.94it/s, loss=2.890, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  11%|█▏        | 24/212 [00:12<01:35,  1.96it/s, loss=1.062, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  12%|█▏        | 25/212 [00:12<01:34,  1.98it/s, loss=0.893, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  12%|█▏        | 26/212 [00:13<01:33,  1.99it/s, loss=0.877, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  13%|█▎        | 27/212 [00:13<01:31,  2.01it/s, loss=0.873, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  13%|█▎        | 28/212 [00:13<01:30,  2.02it/s, loss=0.869, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  14%|█▎        | 29/212 [00:14<01:29,  2.05it/s, loss=0.865, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  14%|█▍        | 30/212 [00:14<01:28,  2.05it/s, loss=0.867, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  15%|█▍        | 31/212 [00:15<01:28,  2.06it/s, loss=0.868, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  15%|█▌        | 32/212 [00:15<01:27,  2.07it/s, loss=0.860, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  16%|█▌        | 33/212 [00:15<01:26,  2.08it/s, loss=0.860, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  16%|█▌        | 34/212 [00:16<01:25,  2.09it/s, loss=0.855, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  17%|█▋        | 35/212 [00:16<01:24,  2.10it/s, loss=0.850, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  17%|█▋        | 36/212 [00:17<01:23,  2.10it/s, loss=0.853, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  17%|█▋        | 37/212 [00:17<01:23,  2.10it/s, loss=0.857, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  18%|█▊        | 38/212 [00:17<01:22,  2.12it/s, loss=0.857, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  18%|█▊        | 39/212 [00:18<01:21,  2.13it/s, loss=0.861, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  19%|█▉        | 40/212 [00:18<01:20,  2.13it/s, loss=0.861, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  19%|█▉        | 41/212 [00:19<01:19,  2.15it/s, loss=0.857, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  20%|█▉        | 42/212 [00:19<01:18,  2.16it/s, loss=0.867, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  20%|██        | 43/212 [00:19<01:18,  2.16it/s, loss=0.877, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  21%|██        | 44/212 [00:20<01:17,  2.17it/s, loss=0.870, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  21%|██        | 45/212 [00:20<01:16,  2.18it/s, loss=0.869, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  22%|██▏       | 46/212 [00:21<01:15,  2.19it/s, loss=0.869, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  22%|██▏       | 47/212 [00:21<01:15,  2.19it/s, loss=0.863, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  23%|██▎       | 48/212 [00:21<01:14,  2.20it/s, loss=0.860, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  23%|██▎       | 49/212 [00:22<01:13,  2.21it/s, loss=0.855, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  24%|██▎       | 50/212 [00:22<01:13,  2.22it/s, loss=0.843, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  24%|██▍       | 51/212 [00:22<01:12,  2.23it/s, loss=0.838, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  25%|██▍       | 52/212 [00:23<01:11,  2.23it/s, loss=0.838, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  25%|██▌       | 53/212 [00:23<01:11,  2.23it/s, loss=0.840, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  25%|██▌       | 54/212 [00:24<01:10,  2.24it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  26%|██▌       | 55/212 [00:24<01:09,  2.24it/s, loss=0.837, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  26%|██▋       | 56/212 [00:24<01:09,  2.25it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  27%|██▋       | 57/212 [00:25<01:08,  2.25it/s, loss=0.836, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  27%|██▋       | 58/212 [00:25<01:08,  2.25it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  28%|██▊       | 59/212 [00:26<01:07,  2.26it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  28%|██▊       | 60/212 [00:26<01:07,  2.25it/s, loss=0.833, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  29%|██▉       | 61/212 [00:27<01:07,  2.24it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  29%|██▉       | 62/212 [00:27<01:06,  2.24it/s, loss=0.820, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  30%|██▉       | 63/212 [00:28<01:06,  2.24it/s, loss=0.816, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  30%|███       | 64/212 [00:28<01:06,  2.24it/s, loss=0.830, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  31%|███       | 65/212 [00:29<01:05,  2.24it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  31%|███       | 66/212 [00:29<01:05,  2.23it/s, loss=0.829, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  32%|███▏      | 67/212 [00:30<01:05,  2.23it/s, loss=0.832, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  32%|███▏      | 68/212 [00:30<01:04,  2.23it/s, loss=0.832, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  33%|███▎      | 69/212 [00:30<01:04,  2.23it/s, loss=0.836, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  33%|███▎      | 70/212 [00:31<01:03,  2.23it/s, loss=0.838, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  33%|███▎      | 71/212 [00:31<01:02,  2.24it/s, loss=0.828, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  34%|███▍      | 72/212 [00:32<01:02,  2.24it/s, loss=0.844, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  34%|███▍      | 73/212 [00:32<01:02,  2.24it/s, loss=0.846, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  35%|███▍      | 74/212 [00:33<01:01,  2.24it/s, loss=0.854, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  35%|███▌      | 75/212 [00:33<01:01,  2.25it/s, loss=0.864, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  36%|███▌      | 76/212 [00:33<01:00,  2.25it/s, loss=0.872, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  36%|███▋      | 77/212 [00:34<01:00,  2.24it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  37%|███▋      | 78/212 [00:34<00:59,  2.24it/s, loss=0.856, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  37%|███▋      | 79/212 [00:35<00:59,  2.24it/s, loss=0.856, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  38%|███▊      | 80/212 [00:35<00:58,  2.24it/s, loss=0.858, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  38%|███▊      | 81/212 [00:36<00:58,  2.24it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  39%|███▊      | 82/212 [00:36<00:58,  2.24it/s, loss=0.860, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  39%|███▉      | 83/212 [00:37<00:57,  2.23it/s, loss=0.865, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  40%|███▉      | 84/212 [00:37<00:57,  2.23it/s, loss=1.012, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  40%|████      | 85/212 [00:38<00:57,  2.23it/s, loss=1.016, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  41%|████      | 86/212 [00:38<00:56,  2.22it/s, loss=1.013, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  41%|████      | 87/212 [00:39<00:56,  2.23it/s, loss=1.016, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  42%|████▏     | 88/212 [00:39<00:55,  2.23it/s, loss=1.018, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  42%|████▏     | 89/212 [00:39<00:55,  2.23it/s, loss=1.017, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  42%|████▏     | 90/212 [00:40<00:54,  2.23it/s, loss=1.014, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  43%|████▎     | 91/212 [00:40<00:54,  2.23it/s, loss=1.031, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  43%|████▎     | 92/212 [00:41<00:53,  2.23it/s, loss=1.022, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  44%|████▍     | 93/212 [00:41<00:53,  2.23it/s, loss=1.008, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  44%|████▍     | 94/212 [00:42<00:52,  2.23it/s, loss=1.005, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  45%|████▍     | 95/212 [00:42<00:52,  2.23it/s, loss=1.001, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  45%|████▌     | 96/212 [00:43<00:51,  2.23it/s, loss=0.999, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  46%|████▌     | 97/212 [00:43<00:51,  2.23it/s, loss=1.012, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  46%|████▌     | 98/212 [00:43<00:50,  2.24it/s, loss=1.023, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  47%|████▋     | 99/212 [00:44<00:50,  2.24it/s, loss=1.020, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  47%|████▋     | 100/212 [00:44<00:50,  2.24it/s, loss=1.022, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  48%|████▊     | 101/212 [00:45<00:49,  2.24it/s, loss=1.025, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  48%|████▊     | 102/212 [00:45<00:49,  2.24it/s, loss=1.028, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  49%|████▊     | 103/212 [00:45<00:48,  2.25it/s, loss=1.021, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  49%|████▉     | 104/212 [00:46<00:48,  2.24it/s, loss=0.859, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  50%|████▉     | 105/212 [00:46<00:47,  2.24it/s, loss=0.847, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  50%|█████     | 106/212 [00:47<00:47,  2.24it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  50%|█████     | 107/212 [00:47<00:46,  2.24it/s, loss=0.854, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  51%|█████     | 108/212 [00:48<00:46,  2.24it/s, loss=0.849, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  51%|█████▏    | 109/212 [00:48<00:46,  2.24it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  52%|█████▏    | 110/212 [00:49<00:45,  2.24it/s, loss=0.863, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  52%|█████▏    | 111/212 [00:49<00:45,  2.24it/s, loss=0.859, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  53%|█████▎    | 112/212 [00:49<00:44,  2.24it/s, loss=0.858, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  53%|█████▎    | 113/212 [00:50<00:44,  2.25it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  54%|█████▍    | 114/212 [00:50<00:43,  2.24it/s, loss=0.866, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  54%|█████▍    | 115/212 [00:51<00:43,  2.24it/s, loss=0.872, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  55%|█████▍    | 116/212 [00:51<00:42,  2.24it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  55%|█████▌    | 117/212 [00:52<00:42,  2.24it/s, loss=0.862, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  56%|█████▌    | 118/212 [00:52<00:42,  2.23it/s, loss=0.858, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  56%|█████▌    | 119/212 [00:53<00:41,  2.23it/s, loss=0.855, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  57%|█████▋    | 120/212 [00:53<00:41,  2.23it/s, loss=0.855, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  57%|█████▋    | 121/212 [00:54<00:40,  2.23it/s, loss=0.847, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  58%|█████▊    | 122/212 [00:54<00:40,  2.23it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  58%|█████▊    | 123/212 [00:55<00:39,  2.23it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  58%|█████▊    | 124/212 [00:55<00:39,  2.23it/s, loss=0.853, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  59%|█████▉    | 125/212 [00:55<00:38,  2.23it/s, loss=0.853, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  59%|█████▉    | 126/212 [00:56<00:38,  2.23it/s, loss=0.839, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  60%|█████▉    | 127/212 [00:56<00:38,  2.24it/s, loss=0.840, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  60%|██████    | 128/212 [00:57<00:37,  2.23it/s, loss=0.841, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  61%|██████    | 129/212 [00:57<00:37,  2.23it/s, loss=0.845, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  61%|██████▏   | 130/212 [00:58<00:36,  2.24it/s, loss=0.836, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  62%|██████▏   | 131/212 [00:58<00:36,  2.24it/s, loss=0.837, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  62%|██████▏   | 132/212 [00:59<00:35,  2.24it/s, loss=0.839, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  63%|██████▎   | 133/212 [00:59<00:35,  2.24it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  63%|██████▎   | 134/212 [00:59<00:34,  2.24it/s, loss=0.826, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  64%|██████▎   | 135/212 [01:00<00:34,  2.24it/s, loss=0.820, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  64%|██████▍   | 136/212 [01:00<00:33,  2.24it/s, loss=0.839, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  65%|██████▍   | 137/212 [01:01<00:33,  2.24it/s, loss=0.832, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  65%|██████▌   | 138/212 [01:01<00:32,  2.25it/s, loss=0.838, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  66%|██████▌   | 139/212 [01:01<00:32,  2.25it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  66%|██████▌   | 140/212 [01:02<00:31,  2.25it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  67%|██████▋   | 141/212 [01:02<00:31,  2.25it/s, loss=0.834, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  67%|██████▋   | 142/212 [01:03<00:31,  2.25it/s, loss=0.825, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  67%|██████▋   | 143/212 [01:03<00:30,  2.25it/s, loss=0.827, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  68%|██████▊   | 144/212 [01:03<00:30,  2.26it/s, loss=0.827, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  68%|██████▊   | 145/212 [01:04<00:29,  2.26it/s, loss=0.827, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  69%|██████▉   | 146/212 [01:04<00:29,  2.26it/s, loss=0.833, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  69%|██████▉   | 147/212 [01:05<00:28,  2.26it/s, loss=0.837, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  70%|██████▉   | 148/212 [01:05<00:28,  2.26it/s, loss=0.836, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  70%|███████   | 149/212 [01:05<00:27,  2.27it/s, loss=0.833, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  71%|███████   | 150/212 [01:06<00:27,  2.27it/s, loss=0.828, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  71%|███████   | 151/212 [01:06<00:26,  2.27it/s, loss=0.826, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  72%|███████▏  | 152/212 [01:07<00:26,  2.27it/s, loss=0.822, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  72%|███████▏  | 153/212 [01:07<00:26,  2.27it/s, loss=0.826, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  73%|███████▎  | 154/212 [01:07<00:25,  2.27it/s, loss=0.828, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  73%|███████▎  | 155/212 [01:08<00:25,  2.27it/s, loss=0.822, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  74%|███████▎  | 156/212 [01:08<00:24,  2.27it/s, loss=0.811, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  74%|███████▍  | 157/212 [01:09<00:24,  2.27it/s, loss=0.821, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  75%|███████▍  | 158/212 [01:09<00:23,  2.27it/s, loss=0.814, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  75%|███████▌  | 159/212 [01:10<00:23,  2.27it/s, loss=0.829, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  75%|███████▌  | 160/212 [01:10<00:22,  2.27it/s, loss=0.821, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  76%|███████▌  | 161/212 [01:11<00:22,  2.27it/s, loss=0.819, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  76%|███████▋  | 162/212 [01:11<00:22,  2.27it/s, loss=0.822, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  77%|███████▋  | 163/212 [01:11<00:21,  2.27it/s, loss=0.820, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  77%|███████▋  | 164/212 [01:12<00:21,  2.27it/s, loss=0.813, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  78%|███████▊  | 165/212 [01:12<00:20,  2.27it/s, loss=0.826, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  78%|███████▊  | 166/212 [01:13<00:20,  2.27it/s, loss=0.822, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  79%|███████▉  | 167/212 [01:13<00:19,  2.27it/s, loss=0.829, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  79%|███████▉  | 168/212 [01:14<00:19,  2.27it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  80%|███████▉  | 169/212 [01:14<00:18,  2.27it/s, loss=0.830, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  80%|████████  | 170/212 [01:14<00:18,  2.27it/s, loss=0.845, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  81%|████████  | 171/212 [01:15<00:18,  2.27it/s, loss=0.838, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  81%|████████  | 172/212 [01:15<00:17,  2.27it/s, loss=0.836, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  82%|████████▏ | 173/212 [01:16<00:17,  2.27it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  82%|████████▏ | 174/212 [01:16<00:16,  2.27it/s, loss=0.840, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  83%|████████▎ | 175/212 [01:17<00:16,  2.27it/s, loss=0.844, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  83%|████████▎ | 176/212 [01:17<00:15,  2.27it/s, loss=0.839, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  83%|████████▎ | 177/212 [01:17<00:15,  2.27it/s, loss=0.832, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  84%|████████▍ | 178/212 [01:18<00:14,  2.27it/s, loss=0.833, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  84%|████████▍ | 179/212 [01:18<00:14,  2.27it/s, loss=0.828, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  85%|████████▍ | 180/212 [01:19<00:14,  2.27it/s, loss=0.837, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  85%|████████▌ | 181/212 [01:19<00:13,  2.27it/s, loss=0.840, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  86%|████████▌ | 182/212 [01:20<00:13,  2.27it/s, loss=0.847, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  86%|████████▋ | 183/212 [01:20<00:12,  2.26it/s, loss=0.849, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  87%|████████▋ | 184/212 [01:21<00:12,  2.26it/s, loss=0.858, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  87%|████████▋ | 185/212 [01:21<00:11,  2.26it/s, loss=0.852, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  88%|████████▊ | 186/212 [01:22<00:11,  2.26it/s, loss=0.847, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  88%|████████▊ | 187/212 [01:22<00:11,  2.26it/s, loss=0.835, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  89%|████████▊ | 188/212 [01:23<00:10,  2.26it/s, loss=0.828, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  89%|████████▉ | 189/212 [01:23<00:10,  2.26it/s, loss=0.833, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  90%|████████▉ | 190/212 [01:24<00:09,  2.26it/s, loss=0.821, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  90%|█████████ | 191/212 [01:24<00:09,  2.26it/s, loss=0.830, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  91%|█████████ | 192/212 [01:24<00:08,  2.26it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  91%|█████████ | 193/212 [01:25<00:08,  2.26it/s, loss=0.825, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  92%|█████████▏| 194/212 [01:25<00:07,  2.26it/s, loss=0.819, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  92%|█████████▏| 195/212 [01:26<00:07,  2.26it/s, loss=0.823, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  92%|█████████▏| 196/212 [01:26<00:07,  2.26it/s, loss=0.831, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  93%|█████████▎| 197/212 [01:27<00:06,  2.26it/s, loss=0.829, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  93%|█████████▎| 198/212 [01:27<00:06,  2.26it/s, loss=0.830, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  94%|█████████▍| 199/212 [01:28<00:05,  2.26it/s, loss=0.832, v_num=7hkt]torch.Size([64, 1536])\n",
      "Epoch 0:  94%|█████████▍| 200/212 [01:28<00:05,  2.25it/s, loss=0.845, v_num=7hkt]torch.Size([29, 1536])\n",
      "Epoch 0:  95%|█████████▍| 201/212 [01:29<00:04,  2.25it/s, loss=0.851, v_num=7hkt]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[Atorch.Size([64, 1536])\n",
      "\n",
      "Epoch 0:  95%|█████████▌| 202/212 [01:29<00:04,  2.25it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Epoch 0:  96%|█████████▌| 203/212 [01:29<00:03,  2.26it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Epoch 0:  96%|█████████▌| 204/212 [01:29<00:03,  2.27it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Epoch 0:  97%|█████████▋| 205/212 [01:30<00:03,  2.28it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "torch.Size([1, 1536])\n",
      "\n",
      "Epoch 0:  98%|█████████▊| 207/212 [01:30<00:02,  2.29it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Validating:  64%|██████▎   | 7/11 [00:01<00:00,  6.27it/s]\u001b[Atorch.Size([64, 1536])\n",
      "\n",
      "Epoch 0:  99%|█████████▊| 209/212 [01:30<00:01,  2.31it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Validating:  82%|████████▏ | 9/11 [00:01<00:00,  7.11it/s]\u001b[Atorch.Size([64, 1536])\n",
      "\n",
      "Epoch 0: 100%|█████████▉| 211/212 [01:30<00:00,  2.32it/s, loss=0.851, v_num=7hkt]torch.Size([64, 1536])\n",
      "\n",
      "Epoch 0: 100%|██████████| 212/212 [01:31<00:00,  2.32it/s, loss=0.851, v_num=7hkt]\n",
      "Epoch 0: 100%|██████████| 212/212 [01:31<00:00,  2.32it/s, loss=0.851, v_num=7hkt]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]torch.Size([64, 1536])\n",
      "Testing:   2%|▏         | 1/41 [00:00<00:06,  6.43it/s]torch.Size([64, 1536])\n",
      "Testing:   5%|▍         | 2/41 [00:00<00:05,  6.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1536])\n",
      "Testing:   7%|▋         | 3/41 [00:00<00:05,  6.88it/s]torch.Size([64, 1536])\n",
      "Testing:  10%|▉         | 4/41 [00:00<00:05,  6.97it/s]torch.Size([64, 1536])\n",
      "Testing:  12%|█▏        | 5/41 [00:00<00:05,  7.19it/s]torch.Size([64, 1536])\n",
      "Testing:  15%|█▍        | 6/41 [00:00<00:04,  7.23it/s]torch.Size([64, 1536])\n",
      "Testing:  17%|█▋        | 7/41 [00:00<00:04,  6.94it/s]torch.Size([64, 1536])\n",
      "Testing:  20%|█▉        | 8/41 [00:01<00:04,  6.76it/s]torch.Size([64, 1536])\n",
      "Testing:  22%|██▏       | 9/41 [00:01<00:04,  6.80it/s]torch.Size([64, 1536])\n",
      "Testing:  24%|██▍       | 10/41 [00:01<00:04,  6.61it/s]torch.Size([64, 1536])\n",
      "Testing:  27%|██▋       | 11/41 [00:01<00:04,  6.83it/s]torch.Size([64, 1536])\n",
      "Testing:  29%|██▉       | 12/41 [00:01<00:04,  6.69it/s]torch.Size([64, 1536])\n",
      "Testing:  32%|███▏      | 13/41 [00:01<00:03,  7.27it/s]torch.Size([64, 1536])\n",
      "Testing:  34%|███▍      | 14/41 [00:01<00:03,  7.40it/s]torch.Size([64, 1536])\n",
      "Testing:  37%|███▋      | 15/41 [00:02<00:03,  7.79it/s]torch.Size([64, 1536])\n",
      "Testing:  39%|███▉      | 16/41 [00:02<00:03,  7.94it/s]torch.Size([64, 1536])\n",
      "Testing:  41%|████▏     | 17/41 [00:02<00:03,  7.73it/s]torch.Size([64, 1536])\n",
      "Testing:  44%|████▍     | 18/41 [00:02<00:02,  8.11it/s]torch.Size([64, 1536])\n",
      "Testing:  46%|████▋     | 19/41 [00:02<00:02,  8.18it/s]torch.Size([5, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  51%|█████     | 21/41 [00:02<00:02,  9.22it/s]torch.Size([64, 1536])\n",
      "Testing:  54%|█████▎    | 22/41 [00:02<00:02,  8.27it/s]torch.Size([64, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  59%|█████▊    | 24/41 [00:03<00:01,  8.81it/s]torch.Size([64, 1536])\n",
      "Testing:  61%|██████    | 25/41 [00:03<00:01,  8.88it/s]torch.Size([64, 1536])\n",
      "Testing:  63%|██████▎   | 26/41 [00:03<00:01,  8.94it/s]torch.Size([64, 1536])\n",
      "Testing:  66%|██████▌   | 27/41 [00:03<00:01,  8.73it/s]torch.Size([64, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  71%|███████   | 29/41 [00:03<00:01,  9.29it/s]torch.Size([64, 1536])\n",
      "Testing:  73%|███████▎  | 30/41 [00:03<00:01,  8.96it/s]torch.Size([64, 1536])\n",
      "Testing:  76%|███████▌  | 31/41 [00:03<00:01,  8.90it/s]torch.Size([64, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  80%|████████  | 33/41 [00:04<00:00,  9.56it/s]torch.Size([64, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  85%|████████▌ | 35/41 [00:04<00:00,  9.65it/s]torch.Size([64, 1536])\n",
      "Testing:  88%|████████▊ | 36/41 [00:04<00:00,  9.65it/s]torch.Size([64, 1536])\n",
      "Testing:  90%|█████████ | 37/41 [00:04<00:00,  9.27it/s]torch.Size([64, 1536])\n",
      "torch.Size([64, 1536])\n",
      "Testing:  95%|█████████▌| 39/41 [00:04<00:00,  9.51it/s]torch.Size([64, 1536])\n",
      "Testing:  98%|█████████▊| 40/41 [00:04<00:00,  8.93it/s]torch.Size([64, 1536])\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8729),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:1 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8729),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:2 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8454),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:3 TEST RESULTS\n",
      "{'test_acc': 0.53125,\n",
      " 'test_f1': 0.23129251700680273,\n",
      " 'test_loss': tensor(1.0694),\n",
      " 'test_precision': 0.17708333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:4 TEST RESULTS\n",
      "{'test_acc': 0.75,\n",
      " 'test_f1': 0.28571428571428575,\n",
      " 'test_loss': tensor(0.7791),\n",
      " 'test_precision': 0.25396825396825395,\n",
      " 'test_recall': 0.32653061224489793}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:5 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8642),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:6 TEST RESULTS\n",
      "{'test_acc': 0.703125,\n",
      " 'test_f1': 0.27522935779816515,\n",
      " 'test_loss': tensor(0.8121),\n",
      " 'test_precision': 0.234375,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:7 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8237),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:8 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8194),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:9 TEST RESULTS\n",
      "{'test_acc': 0.578125,\n",
      " 'test_f1': 0.2442244224422442,\n",
      " 'test_loss': tensor(0.9853),\n",
      " 'test_precision': 0.19576719576719578,\n",
      " 'test_recall': 0.32456140350877194}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:10 TEST RESULTS\n",
      "{'test_acc': 0.734375,\n",
      " 'test_f1': 0.2822822822822823,\n",
      " 'test_loss': tensor(0.7587),\n",
      " 'test_precision': 0.24479166666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:11 TEST RESULTS\n",
      "{'test_acc': 0.71875,\n",
      " 'test_f1': 0.27878787878787875,\n",
      " 'test_loss': tensor(0.7876),\n",
      " 'test_precision': 0.23958333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:12 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8327),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:13 TEST RESULTS\n",
      "{'test_acc': 0.671875,\n",
      " 'test_f1': 0.2679127725856698,\n",
      " 'test_loss': tensor(1.0459),\n",
      " 'test_precision': 0.22751322751322753,\n",
      " 'test_recall': 0.32575757575757575}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:14 TEST RESULTS\n",
      "{'test_acc': 0.734375,\n",
      " 'test_f1': 0.2822822822822823,\n",
      " 'test_loss': tensor(0.7587),\n",
      " 'test_precision': 0.24479166666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:15 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8858),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:16 TEST RESULTS\n",
      "{'test_acc': 0.671875,\n",
      " 'test_f1': 0.26791277258566976,\n",
      " 'test_loss': tensor(0.8570),\n",
      " 'test_precision': 0.22395833333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:17 TEST RESULTS\n",
      "{'test_acc': 0.625,\n",
      " 'test_f1': 0.25641025641025644,\n",
      " 'test_loss': tensor(0.9047),\n",
      " 'test_precision': 0.20833333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:18 TEST RESULTS\n",
      "{'test_acc': 0.640625,\n",
      " 'test_f1': 0.2603174603174603,\n",
      " 'test_loss': tensor(1.0055),\n",
      " 'test_precision': 0.21693121693121695,\n",
      " 'test_recall': 0.3253968253968254}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:19 TEST RESULTS\n",
      "{'test_acc': 0.8,\n",
      " 'test_f1': 0.4444444444444445,\n",
      " 'test_loss': tensor(0.6520),\n",
      " 'test_precision': 0.4,\n",
      " 'test_recall': 0.5}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:20 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8281),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:21 TEST RESULTS\n",
      "{'test_acc': 0.640625,\n",
      " 'test_f1': 0.26031746031746034,\n",
      " 'test_loss': tensor(0.8888),\n",
      " 'test_precision': 0.21354166666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:22 TEST RESULTS\n",
      "{'test_acc': 0.734375,\n",
      " 'test_f1': 0.2822822822822823,\n",
      " 'test_loss': tensor(0.7587),\n",
      " 'test_precision': 0.24479166666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:23 TEST RESULTS\n",
      "{'test_acc': 0.640625,\n",
      " 'test_f1': 0.26031746031746034,\n",
      " 'test_loss': tensor(0.8974),\n",
      " 'test_precision': 0.21354166666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:24 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8367),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:25 TEST RESULTS\n",
      "{'test_acc': 0.765625,\n",
      " 'test_f1': 0.2890855457227139,\n",
      " 'test_loss': tensor(0.7139),\n",
      " 'test_precision': 0.2552083333333333,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:26 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8729),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:27 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8194),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:28 TEST RESULTS\n",
      "{'test_acc': 0.671875,\n",
      " 'test_f1': 0.26791277258566976,\n",
      " 'test_loss': tensor(0.8570),\n",
      " 'test_precision': 0.22395833333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:29 TEST RESULTS\n",
      "{'test_acc': 0.71875,\n",
      " 'test_f1': 0.27878787878787875,\n",
      " 'test_loss': tensor(0.7876),\n",
      " 'test_precision': 0.23958333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:30 TEST RESULTS\n",
      "{'test_acc': 0.65625,\n",
      " 'test_f1': 0.2641509433962264,\n",
      " 'test_loss': tensor(0.8599),\n",
      " 'test_precision': 0.21875,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:31 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8324),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:32 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8367),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:33 TEST RESULTS\n",
      "{'test_acc': 0.625,\n",
      " 'test_f1': 0.25641025641025644,\n",
      " 'test_loss': tensor(0.9436),\n",
      " 'test_precision': 0.20833333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:34 TEST RESULTS\n",
      "{'test_acc': 0.71875,\n",
      " 'test_f1': 0.27878787878787875,\n",
      " 'test_loss': tensor(0.7659),\n",
      " 'test_precision': 0.23958333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:35 TEST RESULTS\n",
      "{'test_acc': 0.71875,\n",
      " 'test_f1': 0.27878787878787875,\n",
      " 'test_loss': tensor(0.7789),\n",
      " 'test_precision': 0.23958333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:36 TEST RESULTS\n",
      "{'test_acc': 0.703125,\n",
      " 'test_f1': 0.27522935779816515,\n",
      " 'test_loss': tensor(0.7992),\n",
      " 'test_precision': 0.234375,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:37 TEST RESULTS\n",
      "{'test_acc': 0.765625,\n",
      " 'test_f1': 0.2890855457227139,\n",
      " 'test_loss': tensor(0.7182),\n",
      " 'test_precision': 0.2552083333333333,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:38 TEST RESULTS\n",
      "{'test_acc': 0.6875,\n",
      " 'test_f1': 0.2716049382716049,\n",
      " 'test_loss': tensor(0.8281),\n",
      " 'test_precision': 0.22916666666666666,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:39 TEST RESULTS\n",
      "{'test_acc': 0.71875,\n",
      " 'test_f1': 0.27878787878787875,\n",
      " 'test_loss': tensor(0.7919),\n",
      " 'test_precision': 0.23958333333333334,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:40 TEST RESULTS\n",
      "{'test_acc': 0.703125,\n",
      " 'test_f1': 0.27522935779816515,\n",
      " 'test_loss': tensor(0.8208),\n",
      " 'test_precision': 0.234375,\n",
      " 'test_recall': 0.3333333333333333}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 41/41 [00:05<00:00,  8.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.872868537902832,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.8728684186935425,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.8453578948974609,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 1.0694180727005005,\n",
       "  'test_precision': 0.17708333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.53125,\n",
       "  'test_f1': 0.23129251700680273},\n",
       " {'test_loss': 0.7790889739990234,\n",
       "  'test_precision': 0.25396825396825395,\n",
       "  'test_recall': 0.32653061224489793,\n",
       "  'test_acc': 0.75,\n",
       "  'test_f1': 0.28571428571428575},\n",
       " {'test_loss': 0.8642175197601318,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.812138557434082,\n",
       "  'test_precision': 0.234375,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.703125,\n",
       "  'test_f1': 0.27522935779816515},\n",
       " {'test_loss': 0.8237310647964478,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.8194056749343872,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.9852616786956787,\n",
       "  'test_precision': 0.19576719576719578,\n",
       "  'test_recall': 0.32456140350877194,\n",
       "  'test_acc': 0.578125,\n",
       "  'test_f1': 0.2442244224422442},\n",
       " {'test_loss': 0.7586754560470581,\n",
       "  'test_precision': 0.24479166666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.734375,\n",
       "  'test_f1': 0.2822822822822823},\n",
       " {'test_loss': 0.7875699996948242,\n",
       "  'test_precision': 0.23958333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.71875,\n",
       "  'test_f1': 0.27878787878787875},\n",
       " {'test_loss': 0.8326677083969116,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 1.0458952188491821,\n",
       "  'test_precision': 0.22751322751322753,\n",
       "  'test_recall': 0.32575757575757575,\n",
       "  'test_acc': 0.671875,\n",
       "  'test_f1': 0.2679127725856698},\n",
       " {'test_loss': 0.7586754560470581,\n",
       "  'test_precision': 0.24479166666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.734375,\n",
       "  'test_f1': 0.2822822822822823},\n",
       " {'test_loss': 0.8858447074890137,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.8569506406784058,\n",
       "  'test_precision': 0.22395833333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.671875,\n",
       "  'test_f1': 0.26791277258566976},\n",
       " {'test_loss': 0.904704213142395,\n",
       "  'test_precision': 0.20833333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.625,\n",
       "  'test_f1': 0.25641025641025644},\n",
       " {'test_loss': 1.005515694618225,\n",
       "  'test_precision': 0.21693121693121695,\n",
       "  'test_recall': 0.3253968253968254,\n",
       "  'test_acc': 0.640625,\n",
       "  'test_f1': 0.2603174603174603},\n",
       " {'test_loss': 0.6520265340805054,\n",
       "  'test_precision': 0.4,\n",
       "  'test_recall': 0.5,\n",
       "  'test_acc': 0.8,\n",
       "  'test_f1': 0.4444444444444445},\n",
       " {'test_loss': 0.8280565738677979,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.8887863159179688,\n",
       "  'test_precision': 0.21354166666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.640625,\n",
       "  'test_f1': 0.26031746031746034},\n",
       " {'test_loss': 0.7586756944656372,\n",
       "  'test_precision': 0.24479166666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.734375,\n",
       "  'test_f1': 0.2822822822822823},\n",
       " {'test_loss': 0.8974370956420898,\n",
       "  'test_precision': 0.21354166666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.640625,\n",
       "  'test_f1': 0.26031746031746034},\n",
       " {'test_loss': 0.8367068767547607,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.713863730430603,\n",
       "  'test_precision': 0.2552083333333333,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.765625,\n",
       "  'test_f1': 0.2890855457227139},\n",
       " {'test_loss': 0.8728684186935425,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.8194056749343872,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.8569507598876953,\n",
       "  'test_precision': 0.22395833333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.671875,\n",
       "  'test_f1': 0.26791277258566976},\n",
       " {'test_loss': 0.7875699996948242,\n",
       "  'test_precision': 0.23958333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.71875,\n",
       "  'test_f1': 0.27878787878787875},\n",
       " {'test_loss': 0.8598921298980713,\n",
       "  'test_precision': 0.21875,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.65625,\n",
       "  'test_f1': 0.2641509433962264},\n",
       " {'test_loss': 0.8323818445205688,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.8367072343826294,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.943632960319519,\n",
       "  'test_precision': 0.20833333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.625,\n",
       "  'test_f1': 0.25641025641025644},\n",
       " {'test_loss': 0.7659426927566528,\n",
       "  'test_precision': 0.23958333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.71875,\n",
       "  'test_f1': 0.27878787878787875},\n",
       " {'test_loss': 0.778918981552124,\n",
       "  'test_precision': 0.23958333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.71875,\n",
       "  'test_f1': 0.27878787878787875},\n",
       " {'test_loss': 0.7991623878479004,\n",
       "  'test_precision': 0.234375,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.703125,\n",
       "  'test_f1': 0.27522935779816515},\n",
       " {'test_loss': 0.7181891202926636,\n",
       "  'test_precision': 0.2552083333333333,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.765625,\n",
       "  'test_f1': 0.2890855457227139},\n",
       " {'test_loss': 0.8280564546585083,\n",
       "  'test_precision': 0.22916666666666666,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.6875,\n",
       "  'test_f1': 0.2716049382716049},\n",
       " {'test_loss': 0.7918952703475952,\n",
       "  'test_precision': 0.23958333333333334,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.71875,\n",
       "  'test_f1': 0.27878787878787875},\n",
       " {'test_loss': 0.8207892179489136,\n",
       "  'test_precision': 0.234375,\n",
       "  'test_recall': 0.3333333333333333,\n",
       "  'test_acc': 0.703125,\n",
       "  'test_f1': 0.27522935779816515}]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda1b4d65181bfe435290e55078ed6e0090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
